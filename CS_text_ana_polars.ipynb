{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FxSOk97fN7E",
        "outputId": "583a56bb-d707-4453-dd92-5533b2df2640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "from datasets import Dataset\n",
        "import polars as pl\n",
        "import json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FFsj-j4ofUNd"
      },
      "outputs": [],
      "source": [
        "#from datasets import load_dataset, Dataset\n",
        "\n",
        "sheet_url=\"/content/drive/MyDrive/Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "MX020uhbfar0",
        "outputId": "791f8587-1ccd-4173-ad40-3b984d259c46"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nAnalytical Plan\\n\\n\\n\\n1. Exploratory Data Analysis (EDA)\\nBefore modeling, perform in-depth EDA to understand:\\n\\n\\n\\nData Distribution: How many unique intents, categories, and flags exist? Are they balanced?\\n\\nText Analysis:\\nLength of instruction and response (word count, character count).\\nMost frequent words/n-grams per intent (using word clouds or bar plots).\\nSentiment analysis (if relevant).\\nFlag Analysis:\\nRelationship between flags and intent (e.g., do certain flags correlate with specific intents?).\\nIntent-Category Relationship:\\nHierarchical structure? Can category help predict intent?\\n2. Intent Prediction Models (Easy → Complex)\\nBaseline Models (Easy)\\n\\n\\n\\nTF-IDF + Logistic Regression / SVM\\n\\n\\n\\nVectorize text (instruction or response) using TF-IDF.\\nTrain a simple classifier (Logistic Regression or SVM) to predict intent.\\nPros: Easy to implement, interpretable.\\nCons: Ignores word order and context.\\n\\n\\n\\nTF-IDF + Random Forest / XGBoost\\n\\n\\n\\nHandles non-linearity better than LR/SVM but may overfit without tuning.\\nIntermediate Models\\nWord Embeddings (FastText, GloVe) + ML\\n\\n\\n\\nUse pre-trained embeddings to represent text as dense vectors (average or max pooling).\\nTrain a classifier (e.g., XGBoost) on top.\\nPros: Captures semantic meaning better than TF-IDF.\\nSimple Neural Networks (e.g., MLP)\\n\\n\\n\\nFeed word embeddings into a shallow neural network.\\nExample architecture:\\nEmbedding Layer → Flatten → Dense → Softmax\\n\\n\\n\\nAdvanced Models (Complex)\\nDeep Learning with RNNs/LSTMs\\n\\n\\n\\nModel sequential context using LSTM/GRU:\\nEmbedding → LSTM → Dense → Softmax\\n\\n\\n\\nPros: Captures word order and long-range dependencies.\\nTransformer-Based Models (BERT, DistilBERT, etc.)\\n\\n\\n\\nFine-tune a pre-trained transformer (e.g., BERT) on your dataset.\\nSteps:\\nTokenize text.\\nFeed into BERT, use [CLS] token for classification.\\nAdd a dense layer on top for intent prediction.\\nPros: State-of-the-art performance, understands context deeply.\\nCons: Computationally expensive.\\n3. Additional Enhancements\\nMulti-Task Learning: Predict intent and category simultaneously.\\nData Augmentation: If data is sparse, use back-translation or synonym replacement.\\nEnsemble Models: Combine predictions from TF-IDF + BERT for robustness.\\n4. Evaluation Metrics\\nAccuracy: Overall correctness (if classes are balanced).\\nPrecision/Recall/F1: For imbalanced datasets.\\nConfusion Matrix: Identify misclassified intents.\\n5. Deployment Considerations\\nFor production, prioritize models with low latency (e.g., DistilBERT over BERT).\\nUse ONNX or quantization to optimize speed.\\nExample Pipeline\\n# Baseline (TF-IDF + Logistic Regression)\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.pipeline import Pipeline\\n\\n\\n\\npipeline = Pipeline([\\n \\xa0\\xa0 (\\'tfidf\\', TfidfVectorizer()),\\n \\xa0\\xa0 (\\'clf\\', LogisticRegression())\\n])\\npipeline.fit(X_train, y_train)\\n\\n\\n\\n# Advanced (BERT Fine-Tuning)\\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\\nimport tensorflow as tf\\n\\n\\n\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-uncased\\')\\nmodel = TFBertForSequenceClassification.from_pretrained(\\'bert-base-uncased\\', num_labels=num_intents)\\n\\n\\n\\ninputs = tokenizer(instructions, padding=True, truncation=True, return_tensors=\"tf\")\\noutputs = model(inputs)\\ny\\n\\n\\nNext Steps\\nStart with TF-IDF + Logistic Regression as a baseline.\\nGradually move to BERT while comparing performance gains.\\nAnalyze misclassifications to improve data/model.\\n\\n\\n\\n'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Analytical Plan\n",
        "\n",
        "\n",
        "\n",
        "1. Exploratory Data Analysis (EDA)\n",
        "Before modeling, perform in-depth EDA to understand:\n",
        "\n",
        "\n",
        "Data Distribution: How many unique intents, categories, and flags exist? Are they balanced?\n",
        "\n",
        "Text Analysis:\n",
        "Length of instruction and response (word count, character count).\n",
        "Most frequent words/n-grams per intent (using word clouds or bar plots).\n",
        "\n",
        "Flag Analysis:\n",
        "TBA\n",
        "\n",
        "2. Intent Prediction Models (Easy → Complex)\n",
        "Baseline Models (Easy)\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ9GgxNNmNpR"
      },
      "outputs": [],
      "source": [
        "df = pl.read_csv(\n",
        "    sheet_url,\n",
        ")\n",
        "respon = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "5wBHYBsIWccd",
        "outputId": "95ebc493-756f-4ac4-ab5c-aaf344618d35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (27, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>intent</th><th>count_of_intent</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;check_invoice&quot;</td><td>1000</td></tr><tr><td>&quot;check_cancellation_fee&quot;</td><td>950</td></tr><tr><td>&quot;review&quot;</td><td>997</td></tr><tr><td>&quot;contact_customer_service&quot;</td><td>1000</td></tr><tr><td>&quot;change_order&quot;</td><td>997</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;complaint&quot;</td><td>1000</td></tr><tr><td>&quot;newsletter_subscription&quot;</td><td>999</td></tr><tr><td>&quot;registration_problems&quot;</td><td>999</td></tr><tr><td>&quot;check_payment_methods&quot;</td><td>999</td></tr><tr><td>&quot;cancel_order&quot;</td><td>998</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (27, 2)\n",
              "┌──────────────────────────┬─────────────────┐\n",
              "│ intent                   ┆ count_of_intent │\n",
              "│ ---                      ┆ ---             │\n",
              "│ str                      ┆ u32             │\n",
              "╞══════════════════════════╪═════════════════╡\n",
              "│ check_invoice            ┆ 1000            │\n",
              "│ check_cancellation_fee   ┆ 950             │\n",
              "│ review                   ┆ 997             │\n",
              "│ contact_customer_service ┆ 1000            │\n",
              "│ change_order             ┆ 997             │\n",
              "│ …                        ┆ …               │\n",
              "│ complaint                ┆ 1000            │\n",
              "│ newsletter_subscription  ┆ 999             │\n",
              "│ registration_problems    ┆ 999             │\n",
              "│ check_payment_methods    ┆ 999             │\n",
              "│ cancel_order             ┆ 998             │\n",
              "└──────────────────────────┴─────────────────┘"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "respon.group_by(\"intent\").agg([\n",
        "  pl.col(\"instruction\").count().alias(\"count_of_intent\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NZ2tT9YSn5n1"
      },
      "outputs": [],
      "source": [
        "def analyze_data_distribution(df):\n",
        "  results = {\n",
        "      'shape': respon.shape,\n",
        "      'total_samples': respon.height,\n",
        "      'intents': {\n",
        "      'unique_count': respon['intent'].n_unique(),\n",
        "      'value_counts': respon['intent'].value_counts(sort=True),\n",
        "      'is_balanced': None\n",
        "      },\n",
        "      'categories': {\n",
        "      'unique_count': respon['category'].n_unique(),\n",
        "      'value_counts': respon['category'].value_counts(sort=True),\n",
        "      'is_balanced': None\n",
        "      },\n",
        "      'flags': {\n",
        "      'unique_count': respon['flags'].n_unique(),\n",
        "      'value_counts': respon['flags'].value_counts(sort=True),\n",
        "      'is_balanced': None\n",
        "      }\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  # Determine if distributions are balanced (heuristic: no class > 50% of total)\n",
        "  for col in ['intents', 'categories', 'flags']:\n",
        "    value_counts = results[col]['value_counts']\n",
        "    max_percentage = (value_counts['count'].max() / results['total_samples']) * 100\n",
        "    results[col]['is_balanced'] = max_percentage < 50\n",
        "\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "def print_analysis_results(results):\n",
        "  print(f\"Total samples: {results['total_samples']}\\n\")\n",
        "\n",
        "  for col in ['intents', 'categories', 'flags']:\n",
        "    print(f\"=== {col.upper()} ===\")\n",
        "    print(f\"Unique {col}: {results[col]['unique_count']}\")\n",
        "    print(f\"Distribution (top 5):\")\n",
        "    print(results[col]['value_counts'].head(5))\n",
        "    print(f\"Is balanced: {'Yes' if results[col]['is_balanced'] else 'No'}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ouyc0ZNW8_0",
        "outputId": "8004ef1e-ad0b-44cc-c9e2-38f9f6dd0dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 26872\n",
            "\n",
            "=== INTENTS ===\n",
            "Unique intents: 27\n",
            "Distribution (top 5):\n",
            "shape: (5, 2)\n",
            "┌──────────────────────────┬───────┐\n",
            "│ intent                   ┆ count │\n",
            "│ ---                      ┆ ---   │\n",
            "│ str                      ┆ u32   │\n",
            "╞══════════════════════════╪═══════╡\n",
            "│ check_invoice            ┆ 1000  │\n",
            "│ complaint                ┆ 1000  │\n",
            "│ contact_customer_service ┆ 1000  │\n",
            "│ edit_account             ┆ 1000  │\n",
            "│ switch_account           ┆ 1000  │\n",
            "└──────────────────────────┴───────┘\n",
            "Is balanced: Yes\n",
            "\n",
            "\n",
            "=== CATEGORIES ===\n",
            "Unique categories: 11\n",
            "Distribution (top 5):\n",
            "shape: (5, 2)\n",
            "┌──────────┬───────┐\n",
            "│ category ┆ count │\n",
            "│ ---      ┆ ---   │\n",
            "│ str      ┆ u32   │\n",
            "╞══════════╪═══════╡\n",
            "│ ACCOUNT  ┆ 5986  │\n",
            "│ ORDER    ┆ 3988  │\n",
            "│ REFUND   ┆ 2992  │\n",
            "│ INVOICE  ┆ 1999  │\n",
            "│ CONTACT  ┆ 1999  │\n",
            "└──────────┴───────┘\n",
            "Is balanced: Yes\n",
            "\n",
            "\n",
            "=== FLAGS ===\n",
            "Unique flags: 394\n",
            "Distribution (top 5):\n",
            "shape: (5, 2)\n",
            "┌───────┬───────┐\n",
            "│ flags ┆ count │\n",
            "│ ---   ┆ ---   │\n",
            "│ str   ┆ u32   │\n",
            "╞═══════╪═══════╡\n",
            "│ BL    ┆ 5212  │\n",
            "│ BLQ   ┆ 2467  │\n",
            "│ BIL   ┆ 2138  │\n",
            "│ BLM   ┆ 1297  │\n",
            "│ BILQ  ┆ 1057  │\n",
            "└───────┴───────┘\n",
            "Is balanced: Yes\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results=analyze_data_distribution(respon)\n",
        "\n",
        "print_analysis_results(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZDSH8ZRA2iY3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jtJ6KkARs8E"
      },
      "source": [
        "| Component              | First Block                     | Second Block                                           |\n",
        "| ---------------------- | ------------------------------- | ------------------------------------------------------ |\n",
        "| Data analyzed          | `instruction`                   | `response`                                             |\n",
        "| Output dictionary name | `instruction_ngrams_per_intent` | `response_ngrams_per_intent`                           |\n",
        "| Print statement labels | \"Top Unigrams / Bigrams\"        | \"Top Unigrams in Responses / Top Bigrams in Responses\" |\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
